{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "from src.data_processing import *\n",
    "\n",
    "os.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and processor\n",
    "MODEL_ID = \"Cnam-LMSSC/wav2vec2-french-phonemizer\"\n",
    "model = AutoModelForCTC.from_pretrained(MODEL_ID)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tests id of the 10 selected readingTestFluencE tests\n",
    "tests_id = [\n",
    "    '2BB671AA-2F6A-4346-8B76-F0C89C236390',\n",
    "    '3B545E56-D802-4380-9993-21C11066B12E',\n",
    "    '5C1C826F-E778-48C3-9170-6BF943175984',\n",
    "    '046E4FEB-E284-48D5-922E-616DA7651F02',\n",
    "    '75A80925-F8CF-463D-AFED-5CC399848CC2',\n",
    "    '102DCD09-43EA-434D-A590-0FA5C7C7C1B3',\n",
    "    '098522E8-2203-425E-85E5-5809D5B0B523',\n",
    "    '79055215-1979-42D3-9B26-B9C6DD935D83',\n",
    "    'ABD81BE7-7629-4816-8241-7ECBF32DFFFA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/xrv1vh8j0k99dnh2mwl662xc0000gn/T/ipykernel_32429/537599615.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  readingTestFluencE_df['testResults'] = readingTestFluencE_df['testResults'].apply(lambda x: convert_str_to_dct_eval(x))\n",
      "/var/folders/kn/xrv1vh8j0k99dnh2mwl662xc0000gn/T/ipykernel_32429/537599615.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  readingTestFluencE_df['evaluationResults'] = readingTestFluencE_df['evaluationResults'].apply(lambda x: convert_str_to_dct_eval(x))\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "data_path = 'data/df_test_cleaned.csv'\n",
    "tests_df = pd.read_csv(data_path)\n",
    "\n",
    "# We only keep the rows where the testType is readingTestFluencE\n",
    "readingTestFluencE_df = tests_df[tests_df['testType'] == 'readingTestFluencE']\n",
    "\n",
    "# Apply conversion functions to testResults and evaluationResults columns\n",
    "readingTestFluencE_df['testResults'] = readingTestFluencE_df['testResults'].apply(lambda x: convert_str_to_dct_eval(x))\n",
    "readingTestFluencE_df['evaluationResults'] = readingTestFluencE_df['evaluationResults'].apply(lambda x: convert_str_to_dct_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_2BB671AA-2F6A-4346-8B76-F0C89C236390_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_3B545E56-D802-4380-9993-21C11066B12E_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_5C1C826F-E778-48C3-9170-6BF943175984_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_046E4FEB-E284-48D5-922E-616DA7651F02_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_75A80925-F8CF-463D-AFED-5CC399848CC2_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_102DCD09-43EA-434D-A590-0FA5C7C7C1B3_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_098522E8-2203-425E-85E5-5809D5B0B523_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_79055215-1979-42D3-9B26-B9C6DD935D83_phonemes.csv\n",
      "Filtered top-3 phoneme transcriptions saved to sample_readingTestFluencE/readingTestFluencE_ABD81BE7-7629-4816-8241-7ECBF32DFFFA_phonemes.csv\n"
     ]
    }
   ],
   "source": [
    "# We iterate over the tests_id and we create the top-3 phoneme transcriptions\n",
    "for test_id in tests_id:\n",
    "    # We extract the audio file\n",
    "    audio_file = f\"sample_readingTestFluencE/readingTestFluencE_{test_id}.wav\"\n",
    "    audio, _ = sf.read(audio_file)\n",
    "\n",
    "    # Preprocess the audio and prepare the inputs for the model\n",
    "    inputs = processor(np.array(audio), sampling_rate=16_000., return_tensors=\"pt\")\n",
    "\n",
    "    # Get the model's predictions\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # Get the top-3 most probable phonemes for each timestep\n",
    "    topk_probs, topk_indices = torch.topk(logits, k=3, dim=-1)\n",
    "\n",
    "    # Decode the top-3 predictions for each timestep\n",
    "    filtered_transcriptions = []\n",
    "    last_phoneme_set = None  # Store the last added phoneme set to avoid duplicates\n",
    "\n",
    "    for i in range(topk_indices.shape[1]):  # Iterate over time steps\n",
    "        phonemes = processor.tokenizer.convert_ids_to_tokens(topk_indices[0, i].tolist())\n",
    "\n",
    "        # Skip if the first prediction is '[PAD]' or the first two predictions are '|' and '[PAD]'\n",
    "        if (phonemes[0] == \"[PAD]\") or (phonemes[0] == \"|\" and phonemes[1] == \"[PAD]\"):\n",
    "            continue  # Ignore this timestamp\n",
    "\n",
    "        # Create a tuple of phonemes (excluding '[PAD]' from second and third positions)\n",
    "        phoneme_tuple = (phonemes[0], phonemes[1], phonemes[2])\n",
    "\n",
    "        # Avoid adding consecutive duplicate phoneme sets\n",
    "        if phoneme_tuple != last_phoneme_set:\n",
    "            filtered_transcriptions.append([i] + list(phoneme_tuple))\n",
    "            last_phoneme_set = phoneme_tuple  # Update last seen set\n",
    "\n",
    "    # Define output CSV file name\n",
    "    csv_filename = os.path.splitext(audio_file)[0] + \"_phonemes.csv\"\n",
    "\n",
    "    # Save results to CSV\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestep\", \"Top_1\", \"Top_2\", \"Top_3\"])  # CSV header\n",
    "        writer.writerows(filtered_transcriptions)\n",
    "\n",
    "    print(f\"Filtered top-3 phoneme transcriptions saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(csv_filename):\n",
    "    \"\"\"\n",
    "    Reads the CSV file and returns a list of sets, where each set contains the three possible phonemes per timestamp.\n",
    "    \"\"\"\n",
    "    phoneme_options = []\n",
    "    \n",
    "    with open(csv_filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header\n",
    "        \n",
    "        for row in reader:\n",
    "            _, top1, top2, top3 = row\n",
    "            phoneme_set = {top1}\n",
    "            if top2 != \"[PAD]\":\n",
    "                phoneme_set.add(top2)\n",
    "            if top3 != \"[PAD]\":\n",
    "                phoneme_set.add(top3)\n",
    "            \n",
    "            phoneme_options.append(phoneme_set)\n",
    "    \n",
    "    return phoneme_options\n",
    "\n",
    "def evaluate_sentence(phoneme_options, target_sentence, buffer_size=15):\n",
    "    \"\"\"\n",
    "    Evaluates whether each word in the target sentence was correctly pronounced using a rolling buffer.\n",
    "    - Adds phoneme options to a buffer one at a time.\n",
    "    - Checks if the word can be formed by selecting at most one phoneme per timestamp (while keeping order).\n",
    "    - If a match is found, removes only the tuples in the buffer **that were used** for the current word.\n",
    "    - If the buffer is full and the word is not matched, moves to the next word without clearing the buffer.\n",
    "    Returns a word-by-word evaluation.\n",
    "    \"\"\"\n",
    "    def can_reconstruct_word(buffer, target_word):\n",
    "        \"\"\"\n",
    "        Checks if the target_word can be formed using at most one phoneme per timestamp (while maintaining order).\n",
    "        Returns True and a list of indices used if the word is reconstructed.\n",
    "        Otherwise, returns False and an empty list.\n",
    "        \"\"\"\n",
    "        target_phonemes = list(target_word)  # Convert word to phoneme list\n",
    "        target_index = 0  # Tracks position in target word\n",
    "        used_indices = []  # Stores the buffer indices used to match the word\n",
    "\n",
    "        # print(f\"Buffer: {buffer}\")\n",
    "\n",
    "        for i, phoneme_set in enumerate(buffer):\n",
    "            if target_index < len(target_phonemes) and target_phonemes[target_index] in phoneme_set:\n",
    "                used_indices.append(i)\n",
    "                target_index += 1  # Move to next phoneme\n",
    "\n",
    "            if target_index == len(target_phonemes):  # If all phonemes were found in order\n",
    "                return True, used_indices  # Return True and the indices used\n",
    "\n",
    "        return False, []  # Could not reconstruct the word\n",
    "\n",
    "    words = target_sentence.split(\" \")  # Split sentence into words\n",
    "    buffer = []  # Rolling buffer for phoneme predictions\n",
    "    results = []\n",
    "\n",
    "    for word in words:\n",
    "        # print(\"==\" * 20)\n",
    "        # print(f\"Target word: {word}\")\n",
    "\n",
    "        for _ in range(buffer_size):  # Ensure we don't go beyond buffer size\n",
    "            found, used_indices = can_reconstruct_word(buffer, word)\n",
    "\n",
    "            if found:  # If the word is successfully reconstructed\n",
    "                results.append((word, \"correct\"))\n",
    "                \n",
    "                # Remove only the used elements while keeping order\n",
    "                buffer = [buffer[i] for i in range(len(buffer)) if i not in used_indices]\n",
    "                break  # Move to next word\n",
    "            else:\n",
    "                if phoneme_options:\n",
    "                    buffer.append(phoneme_options.pop(0))\n",
    "\n",
    "        else:  # If no match is found after buffer fills up, move on\n",
    "            results.append((word, \"missed\"))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Test ID: 2BB671AA-2F6A-4346-8B76-F0C89C236390\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 46/57 words read correctly.\n",
      "========================================\n",
      "Test ID: 3B545E56-D802-4380-9993-21C11066B12E\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 54/67 words read correctly.\n",
      "========================================\n",
      "Test ID: 5C1C826F-E778-48C3-9170-6BF943175984\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 110/130 words read correctly.\n",
      "========================================\n",
      "Test ID: 046E4FEB-E284-48D5-922E-616DA7651F02\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 97/110 words read correctly.\n",
      "========================================\n",
      "Test ID: 75A80925-F8CF-463D-AFED-5CC399848CC2\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 71/86 words read correctly.\n",
      "========================================\n",
      "Test ID: 102DCD09-43EA-434D-A590-0FA5C7C7C1B3\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 83/94 words read correctly.\n",
      "========================================\n",
      "Test ID: 098522E8-2203-425E-85E5-5809D5B0B523\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 46/61 words read correctly.\n",
      "========================================\n",
      "Test ID: 79055215-1979-42D3-9B26-B9C6DD935D83\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 74/85 words read correctly.\n",
      "========================================\n",
      "Test ID: ABD81BE7-7629-4816-8241-7ECBF32DFFFA\n",
      "Word-by-word evaluation:\n",
      "\n",
      "Final Score: 51/61 words read correctly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ground_truth = 'sɛ listwaʁ də məsjø pəti ki vi dɑ̃z yn vjɛj mɛzɔ̃ sitye o kœʁ dœ̃ vjø vilaʒ la mɛzɔ̃ ɛt ɑ̃tuʁe dœ̃ ʒaʁdɛ̃ avɛk yn baʁjɛʁ il i a de kɔ̃kɔ̃bʁ de ʃu fʁize tut sɔʁt də leɡymz o fɔ̃ dy ʒaʁdɛ̃ lə pɔʁtijɔ̃ ʁɛst tuʒuʁ fɛʁme puʁ kə ʃjɛ̃ a pys nə seʃap pa ʃjɛ̃ a pysz ɛm sə kuʃe pʁɛ də la pubɛl a lɔ̃bʁ dœ̃n ɔʁɑ̃ʒe kuvɛʁ də fʁyi delisjø ʃjɛ̃ a pysz ɛ ɡuʁmɑ̃ il kʁɔk tu sə ki lyi pas su la dɑ̃ dez ɔʁɑ̃ʒ puʁi ki tɔ̃b syʁ lə sɔl de flœʁ fanez œ̃ mɔʁso də byvaʁ œ̃ ʒuʁ məsjø pəti desid də mɛtʁ ʃjɛ̃ a pys dɑ̃z yn niʃ ʃjɛ̃ a pys nɛm paz ɛtʁ ɑ̃fɛʁme il pʁefɛʁ sɑ̃dɔʁmiʁ ɑ̃ ʁəɡaʁdɑ̃ lez etwal dɑ̃ lə sjɛl tut le nyiz il abwa kɑ̃ məsjø pəti va sə kuʃe məsjø pəti desid də dɔʁmiʁ dɑ̃ lə ɡʁənje də sa ʒɔli mɛzɔ̃ puʁ pʁɑ̃dʁ œ̃ pø də ʁəpoz il nə tʁuv ply lə sɔmɛj yn nyi dɛ̃sɔmni ɔp il sot dy li e uvʁ la ɡʁɑ̃d mal ki sə tʁuv dəvɑ̃ lyi dɑ̃z œ̃ kwɛ̃ sɔ̃bʁ dy ɡʁənje e la syʁpʁiz tut sa vi kil pɑ̃sɛ sɑ̃z istwaʁ lyi ʁəvjɛ̃t ɑ̃ memwaʁ il sɔʁ le muʃwaʁ bʁɔde paʁ sa ɡʁɑ̃mɛʁ se pətit dɑ̃ də lɛ sɔ̃ po də ʃɑ̃bʁ ebʁeʃe yn tɛt də pwasɔ̃ seʃe œ̃ sak plɛ̃ də bijz yn mɔ̃tʁ ki fɛ tik tak tik tak sɔ̃ kaʁnɛ də nɔtz œ̃ bu də lasɛ sɔ̃ vjø tʁɑ̃zistɔʁ a pil sɛ fu kɔm tu se suvniʁ sə buskyl dɑ̃ sa tɛt e il nə pø ʁətniʁ se laʁm demɔsjɔ̃ sa vi nɛ pa sɑ̃z istwaʁ il sə suvjɛ̃t ɛɡzaktəmɑ̃ də la vwa dy pʁezɑ̃tatœʁ meteo lə tɑ̃ va sameljɔʁe dəmɛ̃ ɑ̃ deby də matine syʁ nɔtʁ ʁeʒjɔ̃ sjɛl ʃaʁʒe lapʁɛmidi il sə ʁapɛl le vjɛj pyblisitez aɛma e la salte sɑ̃ va ɔ̃n a tuʒuʁ bəzwɛ̃ də pəti pwa ʃe swa le pʁəmjɛʁ lymjɛʁ dy ʒuʁ penɛtʁ paʁ la pətit fənɛtʁ dy ɡʁənje il ɛt o kœʁ də se suvniʁ kɑ̃ sɔ̃ ʁevɛj sɔndʁɪŋ dʁɪŋ dʁɪŋ'\n",
    "ground_truth = ground_truth.split(\" \")\n",
    "\n",
    "# We iterate over the tests_id and we create the top-3 phoneme transcriptions\n",
    "for test_id in tests_id:\n",
    "    print(\"==\" * 20)\n",
    "    print(f\"Test ID: {test_id}\")\n",
    "\n",
    "    test_row = readingTestFluencE_df[readingTestFluencE_df['id'] == test_id]\n",
    "    evaluation_result = test_row['evaluationResults'].apply(\n",
    "        lambda x: x['wordsState'] if 'wordsState' in x else None).dropna().tolist()\n",
    "\n",
    "    # We extract the ground truth for each test\n",
    "    read_words = [[d for d in row if list(d.values())[0] != \"NonRead\"] for row in evaluation_result]\n",
    "    reference_text = ' '.join([list(d.keys())[0] for row in read_words for d in row])\n",
    "    reference_words = reference_text.split()  \n",
    "    target_sentence = \" \".join(ground_truth[:len(reference_text.split())]) \n",
    "\n",
    "    \n",
    "    csv_filename = f\"sample_readingTestFluencE/readingTestFluencE_{test_id}_phonemes.csv\"\n",
    "\n",
    "    # Load the phoneme predictions\n",
    "    phoneme_options = load_predictions(csv_filename)\n",
    "\n",
    "    # Evaluate each word\n",
    "    word_results = evaluate_sentence(phoneme_options, target_sentence, buffer_size=25)\n",
    "\n",
    "    # Print results\n",
    "    #print(\"Word-by-word evaluation:\")\n",
    "    # for word, status in word_results:\n",
    "    #     status_symbol = \"✅\" if status == \"correct\" else \"❌\"\n",
    "        # print(f\"{status_symbol} {word} → {status}\")\n",
    "\n",
    "    # Summary of correctness\n",
    "    correct_words = sum(1 for _, status in word_results if status == \"correct\")\n",
    "    total_words = len(word_results)\n",
    "    print(f\"\\nFinal Score: {correct_words}/{total_words} words read correctly.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
